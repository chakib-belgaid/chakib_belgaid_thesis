
\section{Introduction}


Dynamic programming languages, with the exception of Perl, have surpassed compiled programming languages in terms of popularity among software system developers over the past decade (cf. Figure~\ref{fig:pypl}).
However, it remains unclear whether this category of dynamic programming languages can truly compete with compiled ones in terms of power consumption.
\begin{figure}[htbp]
    \includegraphics[width=\linewidth]{imgs/programminglanguangespopularity.png}
    \caption{PYPL Popularity of Programming Languages~\cite{noauthor_pypl_nodate}}
    \label{fig:pypl}
\end{figure}

In particular, Noureddine~\emph{et~al.}~\cite{noureddine_preliminary_2012} in 2012, and then Pereira~\emph{et~al.}~\cite{pereira_energy_2017} in 2017, conducted empirical power measurements on this topic, and both concluded that compiled programming languages overcome dynamic ones when it comes to power consumption.
According to their experiments, an interpreted programming language like Python can impose up to a $7,588\,\%$ energy overhead compared to C~\cite{pereira_energy_2017} (cf. Figure~\ref{fig:hannoi}).
In this chapter, we therefore explore the oblivious optimizations that can be applied to Python legacy applications in order to reduce their energy footprint.
As Python is widely adopted by software services deployed in public and private Cloud infrastructures, we believe that our contributions will benefit to wide diversity of legacy systems and not only favorably contribute to reduce the carbon emissions of ICT, b kmoiut also reduce their cloud invoice for the resources consumed by these services.
More specifically, this chapter focuses on runtime optimizations that can adopted by developers to leverage the power consumption of Python applications.
We start by studuing the impact of some of programmers choice such as the type of data structures or loops, on the global energy consumption of the execution code.
then we discuss some other factors such as level of concurrency etc. later we we will talk about another non intrusive ways to optimize the energy consumption of this code. one kind of those optimizations includes alternative interpertersand some libraries that are dedicated to optimize the code without changing its structures such as \emph{ahead-of-time} (AOT) compilation and \emph{just-in-time} (JIT) libraries that are maintained by the community.

%%%%%%%%%%% READ AGAIN 
% articular, Noureddine in 2012 and Pereira in 2017 conducted empirical power measurements on this topic, and both concluded that compiled programming languages consume less power than dynamic ones.They found that a programming language that is interpreted, like Python, can use up to 7,584 times more energy than C. As a result, in this chapter, we will look at the obvious optimizations that may be done to Python legacy programs to lower their energy footprint.Since Python is used by many software services in both public and private cloud infrastructures, we think that our contributions will help a wide range of legacy systems by reducing ICT carbon emissions and lowering cloud bills for the resources used by these services. This chapter focuses on runtime improvements that developers can employ to reduce the power consumption of Python applications.We start by looking at how the choices made by programmers, like the type of data structure or loop, affect how much energy the code as a whole uses. Then we discuss additional topics, such as the level of concurrency, and so on.We will discuss another non-intrusive technique to optimize this code's energy consumption.Alternative interpreters and libraries dedicated to optimizing code without affecting its structures, such as ahead-of-time (AOT) compilation and just-in-time (JIT) libraries maintained by the community, are examples of these optimizations. 
% However, the operational conditions under which these measurements may threaten the validity of their results.



\section{Motivation}
\subsection{python popularity}

Nowadays, Python seems to attract a large community of developers who are interested in data analysis, web development, system administration, and machine learning—according to a survey conducted in 2018 by JetBrains ---\footnote{\url{https://www.jetbrains.com/research/python-developers-survey-2018/}}one can fear that the wide adoption of dynamic programming languages, like Python, in production may critically hamper the power consumption of ICT.
As the popularity of such dynamic programming languages partly builds on the wealth and the diversity of their ecosystem (\emph{e.g.}, the NumPY, SciKit\,Learn, and Panda libraries in Python), one cannot reasonably expect that developers will likely move to an alternative programming language mostly for energy considerations.
Rather, we believe that a better option consists of leveraging the strength of this rich ecosystem to promote energy-efficient solutions in order to improve the power consumption of legacy software systems.




% The contributions of this chapter can therefore be summarized as:
% \begin{compactenum}
%     \item a classification of state-of-the-art Python optimizations,
%     \item an evaluation of the power efficiency of these optimizations on well-known micro-benchmarks,
%     \item a comparison of the effective energy efficiency of Python compared to compiled languages,
%     \item an assessment of the energy speedup of these optimizations on representative applications and workloads.
% \end{compactenum}



\subsection{python gluttony}

In the other hand,because of the interpreted nature of Python code, this programming language has paid a high price in terms of performance.  \ref{fig:clbg}, memory and energy consumption.

\begin{figure}[htbp]
    \includegraphics[width=\linewidth]{imgs/hannoiimplementation.png}
    \caption{Energy consumption of a recursive implementation of Tower of Hanoi program in different languages~\cite{noureddine_preliminary_2012}}
    \label{fig:hannoi}
\end{figure}

According to \cite{pinto_energy_2017} and \cite{noureddine_preliminary_2012}, Python tends to be one more energy hungry . As onne can notice in figure \ref{fig:hannoi}, python consumes 30 times more than C or C++. The test was done on an implementation of \fnurl{hannoi test}{ https://en.wikipedia.org/wiki/Tower_of_Hanoi}  30 disks.

Python consumes a lot of energy, mainly because it is slow in execution. Its flexibility and simplicity caused it to drop off in performance, because Python gains its flexibility from being a dynamic language. Therefore, it needs an interpreter to execute its programs, which makes them much slower compared to the others that are written in compiled programming languages such as C and C++ or semi-compiled languages like Java.

As shown in Table\ref{fig:clbg}, one can see that in most of the test cases, Python takes more time to execute-the only case that he wasn't the last one was in the benchmark regx-redux where he beat Go-, and in some cases the gap was huge, such as in the n-body test where Python took around 100 times more than C++.\footnote{\url{https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html}}
\begin{table}[hbt]
    \begin{tabular}{l|*{5}c}
                           & C    & C++   & Java & python & Go    \\
        \hline
        pidigits           & 1.75 & 1.89  & 3.13 & 3.51   & 2.04  \\
        reverse-complement & 1.75 & 2.95  & 3.31 & 16.76  & 4.00  \\
        regx-redux         & 1.45 & 1.66  & 10.5 & 15.56  & 28.69 \\
        k-nucleotide       & 5.07 & 3.66  & 8.66 & 79.79  & 15.36 \\
        binary-trees       & 2.55 & 2.63  & 8.28 & 92.72  & 28.90 \\
        fasta              & 1.32 & 1.33  & 2.32 & 62.88  & 2.07  \\
        Fannkuch-redux     & 8.72 & 10.62 & 17.9 & 547.23 & 17.82 \\
        n-body             & 9.17 & 8.24  & 22.0 & 882.00 & 21.00 \\
        spectral-norm      & 1.99 & 1.98  & 4.27 & 193.86 & 3.95  \\
        Mandelbort         & 1.64 & 1.51  & 6.96 & 279.68 & 5.47  \\
    \end{tabular}
    \caption{Comparison of the execution time between different programming languages using the computer language benchmarks game}
    \label{fig:clbg}
\end{table}


\subsection{Goal}

To reduce the energy consumption of Python, we started by targeting the main usage of this programming language, which is revealed to be data science and web development. Figure~\ref{fig:usecase} illustrates a study made by the JetBrain company on Python developers. \footnote{\url{https://www.jetbrains.com/lp/python-developers-survey-2020}}.In this survey, multiple answers were accepted. As one can see, 57\% of the respondents said that they use Python for data science, 51\% said they are using it for web development, and around 40\% said they are using it for system administration.
\begin{figure}[hbt]
    \centering
    \includegraphics[width=\linewidth]{imgs/python_use_cases}
    \caption{Use cases of python }
    \label{fig:usecase}
\end{figure}

In this chapter, we will first investigate its behavior in the most common usage cases.Following that, we will focus on the language's structures in the hope of discovering some fundamental guidelines for more general purposes, as \citeauthor{hasan_energy_2016-1} did in their article~\cite{hasan_energy_2016-1}.
Following that, we will measure the energy consumption of several Python implementations in order to determine a non-intrusive technique to improve energy efficiency.
Therefore this chapter will target the following research questions :
\begin{compactenum}[\indent\bf RQ\,1:]
    \item \emph{What is the behavior of Python when it is used as a data science tool?}
    \item \emph{Are the default guidelines of Python energy efficient?}
    \item \emph{Can we reduce the energy consumption of Python programs without impacting the source code?}
\end{compactenum}

For this chapter we are considering 4 separate yet related studies .
First, we are going to see the energy behavior of the python within two study cases. Web servers and machine learning. We will then delve deeper into the energy consumption of Python basic structures before concluding with the impact of Python interpterer on energy consumption.

% \section{Experimental Protocol}\label{sec:pythonprotocol}
% In this section, we discuss the experimental setting, including hardware components, software components, and the methodology that we adopted to answer the previous research questions.
% For each of the questions that follow, we will first talk about how the experiment was done, and then we will talk about the results.


% %% should i include the part with the exceptions ??? naah no need so

% %% except the parallellism part , which i dont know how to link it here yet 
% \section{Workload} :
% for this chapter we are consediring 4 seperated, yet related studies .
% First we are going to see the energy behavriour of python within two study cases. Web servers and Machine learning. later we will dig deeper into the energy consumption of python basic structures where finally we will conclude with the impact of python interpterer on the energy consumption.




% \subsubsection{micro-benchmarks}

% \subsubsection{benchmarks}




\section{web developement}
The purpose of this study is to understand the impact of the \emph{ORMs} (Object Relational Mapping)~\cite{o2008object}. We have chosen django as our web framework

As a result, we create a simple website in which we attempt to analyze the cost of a single request using various mechanisms to retrieve data from the database.

The idea behind this use case is to see whether the choice of the database and the orm (object relational mapper) impacts the energy consumption and the performance of the website.

We considered using two different databases, PostgreSQL and SQlite3, that contained the same data, and three different ways to fetch the data.
\begin{enumerate}
    \item the naive version: which relies only on the ORM to get the data
    \item Prefetch : basically we just prefetch the data before we request it
    \item optimized : and here we optimize our request on the SQL level without passing by the ORM
\end{enumerate}

\begin{figure}[!hbt]
    \centering
    \includegraphics[width=\linewidth]{imgs/django}
    \caption{energy behaviour based on multiprocessing}
    \label{fig:django}
\end{figure}


%%%%% have to rephrase this 

As one can see in figure~\ref{fig:django}, different choices of requesting the data have a huge impact on the energy consumption. as the naive version can consume up to 10x more energy than the optimized one.
In the other hand the choice of the data base didnt have huge impact on the total energy despite their different behaviour regarding the execution time and the average power.
This can be useful to help develeppers make a choice regarding which data base they can use based on the number of the expected requests and the expectation of the performance.

Another interesting observation is the impact of the interpreter, as figure~\ref{fig:django} highligh. the use of Pypy interpter instead of the default one helped reducing the amount of the energy consumption even when we are dealing with the naive version.

Figure \ref{fig:python_multiprocessing} shows the behaviour of python programs when we try to introduce the parallelism.
As we know python is a single threaded program thx to ghe GLS ( global lock system ) howerver due to the increase of the number of cores /threads per cpu it many libraries stared to take advanteage of this feature so most of them they will try to simulate the multithreading by using multiple instances pf the processor % TO VERIFY 

\begin{figure}[hbt]
    \centering
    \includegraphics[width=\linewidth]{imgs/multiprocessing_energyvstime}
    \caption{energy behaviour based on multiprocessing}
    \label{fig:python_multiprocessing}
\end{figure}

as we can see in the graph the energy consumption is correlate with the number of threads until we arrive to the limit of the cores and then we lose the adventage of the multiprocessing , well in that case we pass from parallelism to concurency. where different sub process have to compete for the CPU Ressources.
Another finding is when we hit the number of physical cores. there was an increase of execution time but still reduced energy, the reason behind this is the scheduler of the operating system. basicaly he favorits the hyper threads than the physical core wich will lead to some context switches which cause the slow behaviour, howerver in the other hand the other two physical cores are not consuming energy, neither their hyper threads which explains the gain of the eneryg consumption in this case.
in the Chapter %% reference the work of intern from lyon  
we discuss a deeper this behaviour of the scheduler and in that case we confirm that it is not related to python but it is more generic behaviour %% maybe even this graph should go there 


\subsection{python insights}

The goal of this section is to find some insights where we can optimize the energy consumption without impacting the source code. so we started by extending the work of \citeauthor{hasan_energy_2016} and \citeauthor{oliveira_recommending_nodate} to the python environement.



%%%% concurency 



another field of investigation is the type data and structure conroles. that might impact the energy consumption.
To do so. We iterate over a list using three methodes.
first the classical for ( for i in range (len(n))). howerver as we can see here unlike other porgramming langauges it requires extra operations such as determining the length of the collection , and then using the iterator range. so we tried the more adapted version
( for element in collection). Morever in most programming languages the for loop is translated to a while loop ( transfirmation from D type to B type -- asm -- ), therefore we wanted to compare this with a ( while ) version.
After determining the main ways to iterate over a loop we run the algorithms  collections of different data types to see wether it will impact of the energy consumption of the code, same thing for the size of the collection.

As we can see in figure~\ref{fig:pythonloops} the type of the data hasn't an impact on the energy consumption.In the other hand the way we iterate over the collection has a huge factor. interestely, the for in range loop was by far the optimal one with following by the regural for in collection, and the while part was the least one with an overhead of 400\% compared to the first option.



%%% putting the idea, later i ll reformulate it 
the reason behind a such behaviour is mainly related on how python interpeter is made.
% add refenece https://www.python.org/doc/essays/list2str/ 
%% https://www.pythonpool.com/for-vs-while-loop-python/  
% https://wiki.python.org/moin/TimeComplexity
%% http://python-history.blogspot.com/2010/06/from-list-comprehensions-to-generator.html?m=1
In order to reduce the latency of the python code. most of the buitl-in functions an operations are written in C, same thing goes for the function range, further more the function len has a complexity of O(1) because it is based on the function Py\_SIZE  of C which stores the length in a field for the object.
so basically for the for in range is basically creating a new iterator that has the same length of the first one. and for each iteration we will have to do a second acceess ( l[i]) instead of one one access hence the double time.
for the wile is even slower due to the implicite incrementation of the variable which will cause an extra operation during the loop .
to confirm the hyphothsis. we tried to construct a new list by editing the elements of the previous one. And as predicted , the builtin methodes are the best energy saving, while the customize while loop is the heaviest. an interesting finding is. the impact of annonymous functions ( lambda expressions) on the energy consumption.
the reseason behind this is the fact that python treats those functions as local variables unlike the predifined ones which are global in our case. therefore they are faster and consumes less energy  % same reference https://www.python.org/doc/essays/list2str/ 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/python_iterations}
    \caption{energy behaviour of different python loops }
    \label{fig:pythonloops}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/python_treatemens}
    \caption{energy behaviour of different methodes to change a list}
    \label{fig:pythontreatement}
\end{figure}

\paragraph{conclusion}
This study has shown us, that the optimial way to reduce the energy consumption of the python code is to follow the guidelines and use the builtin functions, which is kinda happy news for the developers since they don't have to make extra effort to make their code green


\subsection{python and multiprocessing}
Figure \ref{fig:python_multiprocessing} shows the behaviour of python programs when we try to introduce the parallelism.
As we know python is a single threaded program thx to ghe GLS ( global lock system ) howerver due to the increase of the number of cores /threads per cpu it many libraries stared to take advanteage of this feature so most of them they will try to simulate the multithreading by using multiple instances pf the processor % TO VERIFY 

\begin{figure}[hbt]
    \centering
    \includegraphics[width=\linewidth]{imgs/multiprocessing_energyvstime}
    \caption{energy behaviour based on multiprocessing}
    \label{fig:python_multiprocessing}
\end{figure}

as we can see in the graph the energy consumption is correlate with the number of threads until we arrive to the limit of the cores and then we lose the adventage of the multiprocessing , well in that case we pass from parallelism to concurency. where different sub process have to compete for the CPU Ressources.
Another finding is when we hit the number of physical cores. there was an increase of execution time but still reduced energy, the reason behind this is the scheduler of the operating system. basicaly he favorits the hyper threads than the physical core wich will lead to some context switches which cause the slow behaviour, howerver in the other hand the other two physical cores are not consuming energy, neither their hyper threads which explains the gain of the eneryg consumption in this case.
in the Chapter %% reference the work of intern from lyon  
we discuss a deeper this behaviour of the scheduler and in that case we confirm that it is not related to python but it is more generic behaviour %% maybe even this graph should go there 

%% todo 
% add performance 
% add dram \ a glimps 

\subsection{Python and machine learning }
Machine learning is becoming an integral part of our daily lives, growing more potent and energy-hungry each year.

As machine learning can have a significant impact on climate change, it is vital to investigate mitigation techniques.

\paragraph{hardware }
Chifflot 8 from Grid 5000's Lille site was used for all of the trials.
The machine is outfitted with two Intel Xeon Gold 6126 CPUs, each having 12 physical cores, 192 GB of RAM, and two 32 GB Tesla V100 GPUs.

\paragraph{software}


For the sake of reproducibility, each experiment is done within a Docker container using Jupyter lab . These tests are run on top of a minimal version of Debian-10 in order to increase the accuracy of the tests by elimanting any unnecessary processes.


\subsubsection{Workload}
\paragraph{Models}

Several models were developed, however only two were used in the final trials because they achieved 94 percent accuracy in an acceptable length of time.
David Page's cifar10-fast and Woonhyuk Baek's torchskeleton are shown here.
\paragraph{Datasets}

The CIFAR-10 dataset was the major source of data for the studies.
It is made up of 60000 32x32 color images grouped into ten categories.

Some experiments were done using the MNIST dataset of handwritten digits to validate the results acquired from the first dataset.
The model did not need to be updated because the 60000 28x28 grayscale photos were padded.


\subsubsection{candidates}
The experiments were run with several different CPU and GPU configurations:

\begin{itemize}
    \item With and without GPU
    \item With and without hyperthreading
    \item Different number of physical cores
\end{itemize}

\subsubsection{metrics}


We used Pytorch 1.10.0  to train those models and pyjoules to measure the energy consumption of the GPU and CPU.
\begin{itemize}
    \item accuracy : in \%
    \item execution time : in seconds for both the duration of each epoch and the total duration to a chieve a certain accuracy
    \item total energy consumption : for the CPU and the  GPU
    \item
\end{itemize}


\section{finding and results}
As the model's accuracy increases, so does the energy required for the next accuracy increment.

Figure \ref{fig:cum_energy_vs_accuracy} depicts how the curve steepens as training progresses.
For example, training to 90\% accuracy requires three times the energy required for training to 80\% accuracy.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/accuracy_basedonepoch}
    \caption{accuracy based on epoch  }
    \label{fig:p2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/cumulative_energy_vs_accuracy}
    \caption{cumulative energy consumption vs accuracy
    }
    \label{fig:cum_energy_vs_accuracy}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/power_gpu_baedonepoche}
    \caption{evolution of average gpu power based on epoch  }
    \label{fig:p2}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/cumulative_energy_fast10}
    \caption{cumulative energy of fast10 benchmark within different configurations }
    \label{fig:p2}
\end{figure}



\paragraph{conclusion}
We discovered that when a model's accuracy improves, so does the energy required for a subsequent accuracy gain.
This begs the question of when we should discontinue training.
Is a 10\% increase in accuracy worth it if we have to spend three times the energy?
Even while utilizing a GPU consumes more total power, the training time is significantly reduced.
As a result, the utilization of a GPU is required to lower the energy consumption of the training.
Some experiments revealed unusual behavior that was not studied during this internship.
These could be examined in future studies and perhaps used to achieve more energy savings.
The execution time did not depend on the number of cores employed in several studies.
This parameter had a significant impact on training time in others.
As a result, the best core configuration will be determined by the script.
The next steps in this area could include exploring the reasons for these discrepancies and possibly creating a script that can automatically find the ideal core configuration for a specific script.





\input{python_interperters.tex}